import os
import splitfolders
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, classification_report

# ==============================
# 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙˆØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ==============================
input_folder = r"C:\Users\am\Downloads\wather\archive\Multi-class Weather Dataset"
output_folder = r"C:\Users\am\Downloads\wather\weather_split"

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
os.makedirs(output_folder, exist_ok=True)

if not os.listdir(output_folder):  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙØ§Ø±ØºØ§Ù‹
    print("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (70% Train, 20% Val, 10% Test)...")
    splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.7, .2, .1))
else:
    print("âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚Ø³Ù…Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹.")

# ==============================
# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ==============================
train_dir = os.path.join(output_folder, "train")
val_dir = os.path.join(output_folder, "val")
test_dir = os.path.join(output_folder, "test")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
for folder in [train_dir, val_dir, test_dir]:
    if not os.path.exists(folder):
        raise FileNotFoundError(f"Ø§Ù„Ù…Ø¬Ù„Ø¯ {folder} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")

# Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    train_dir, 
    target_size=(150, 150), 
    batch_size=32, 
    class_mode='categorical')

val_gen = val_datagen.flow_from_directory(
    val_dir, 
    target_size=(150, 150), 
    batch_size=32, 
    class_mode='categorical')

test_gen = test_datagen.flow_from_directory(
    test_dir, 
    target_size=(150, 150), 
    batch_size=32, 
    class_mode='categorical', 
    shuffle=False)  # Ù…Ù‡Ù… Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ù„Ø§Ø­Ù‚Ø§Ù‹

num_classes = len(train_gen.class_indices)
print(f"ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª: {num_classes} â†’ {list(train_gen.class_indices.keys())}")

# ==============================
# 3. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ CNN
# ==============================
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])
model.summary()

# ==============================
# 4. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==============================
history = model.fit(
    train_gen,
    steps_per_epoch=train_gen.samples // train_gen.batch_size,
    epochs=10,
    validation_data=val_gen,
    validation_steps=val_gen.samples // val_gen.batch_size
)

# ==============================
# 5. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==============================
test_loss, test_acc = model.evaluate(test_gen)
print(f"ğŸ¯ Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {test_acc:.2%}")

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.save("weather_model.h5")
print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: weather_model.h5")

# ==============================
# 6. Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³ ÙˆØ§Ù„ØªÙ‚Ø±ÙŠØ±
# ==============================
# Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
y_true = test_gen.classes
y_pred = model.predict(test_gen)
y_pred_classes = np.argmax(y_pred, axis=1)

# Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
cm = confusion_matrix(y_true, y_pred_classes)
labels = list(test_gen.class_indices.keys())

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
            xticklabels=labels, yticklabels=labels)
plt.xlabel("Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª")
plt.ylabel("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©")
plt.title("Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³")
plt.show()

# ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ
print("\nØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\n")
print(classification_report(y_true, y_pred_classes, target_names=labels))

# Ø±Ø³Ù… Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨')
plt.plot(history.history['val_accuracy'], label='Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚')
plt.title('Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬')
plt.ylabel('Ø§Ù„Ø¯Ù‚Ø©')
plt.xlabel('Ø§Ù„Ø¹ØµØ±')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨')
plt.plot(history.history['val_loss'], label='Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ­Ù‚Ù‚')
plt.title('Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬')
plt.ylabel('Ø§Ù„Ø®Ø³Ø§Ø±Ø©')
plt.xlabel('Ø§Ù„Ø¹ØµØ±')
plt.legend()

plt.tight_layout()
plt.show()